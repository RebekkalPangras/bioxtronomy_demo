{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bioxtronomy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcgBz-8mgmo5",
        "outputId": "600043d3-e5ac-4deb-ad81-cd61c22f8b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/RebekkalPangras/bioxtronomy.git"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bioxtronomy'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 106 (delta 46), reused 82 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 198.52 KiB | 2.96 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_r8dlXLpCNL",
        "outputId": "ef847d4c-868e-427f-f22b-d507529d2b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!python /content/bioxtronomy/train_autoencoder.py --model /content/bioxtronomy/output/autoencoder.h5 --vis /content/bioxtronomy/output/recon_vis.png --plot /content/bioxtronomy/output/plot.png"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-28 13:24:36.101107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "[INFO] loading dataset...\n",
            "[INFO] building autoencoder...\n",
            "2020-10-28 13:24:38.420225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-28 13:24:38.429898: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-28 13:24:38.429954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0e9db6b4bad7): /proc/driver/nvidia/version does not exist\n",
            "2020-10-28 13:24:38.463320: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-10-28 13:24:38.463633: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d48a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-28 13:24:38.463675: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Started Training!\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.1185 - val_loss: 0.1225\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0726 - val_loss: 0.1154\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0728 - val_loss: 0.1109\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0653 - val_loss: 0.1076\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0538 - val_loss: 0.1040\n",
            "[INFO] making predictions...\n",
            "[INFO] saving autoencoder...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm5Bc3h5OG2p",
        "outputId": "ba3138dd-3127-4bd2-88f1-5e8279ae2188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!python /content/bioxtronomy/index_images.py --model /content/bioxtronomy/output/autoencoder.h5 --index /content/bioxtronomy/output/index.pickle"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-28 13:37:02.336077: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "[INFO] loading MNIST training split...\n",
            "[INFO] loading autoencoder model...\n",
            "2020-10-28 13:37:04.455078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-28 13:37:04.464642: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-28 13:37:04.464712: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0e9db6b4bad7): /proc/driver/nvidia/version does not exist\n",
            "2020-10-28 13:37:04.471741: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-10-28 13:37:04.472076: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2340bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-28 13:37:04.472124: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "[INFO] encoding images...\n",
            "[INFO] saving index...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmS0ESENP1qd",
        "outputId": "c91d98c2-b44d-470c-c8ef-66480f03505a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from imutils import build_montages\n",
        "import cv2\n",
        "\n",
        "def euclidean(a, b):\n",
        "\t# compute and return the euclidean distance between two vectors\n",
        "\treturn np.linalg.norm(a - b)\n",
        "\n",
        "def perform_search(queryFeatures, index, maxResults=64):\n",
        "\t# initialize our list of results\n",
        "\tresults = []\n",
        "\n",
        "\t# loop over our index\n",
        "\tfor i in range(0, len(index[\"features\"])):\n",
        "\t\t# compute the euclidean distance between our query features\n",
        "\t\t# and the features for the current image in our index, then\n",
        "\t\t# update our results list with a 2-tuple consisting of the\n",
        "\t\t# computed distance and the index of the image\n",
        "\t\td = euclidean(queryFeatures, index[\"features\"][i])\n",
        "\t\tresults.append((d, i))\n",
        "\n",
        "\t# sort the results and grab the top ones\n",
        "\tresults = sorted(results)[:maxResults]\n",
        "\n",
        "\t# return the list of results\n",
        "\treturn results\n",
        "\n",
        "model = \"/content/bioxtronomy/output/autoencoder.h5\"\n",
        "index = \"/content/bioxtronomy/output/index.pickle\"\n",
        "sample = 2\n",
        "\n",
        "# load the dataset\n",
        "print(\"[INFO] loading dataset...\")\n",
        "\n",
        "# PATH = os.getcwd()\n",
        "\n",
        "train_path = '/content/bioxtronomy/data/train/bio/'\n",
        "train_batch = os.listdir(train_path)\n",
        "x_train = []\n",
        "\n",
        "# if data are in form of images\n",
        "for sample in train_batch:\n",
        "    img_path = train_path + sample\n",
        "    x = image.load_img(img_path, color_mode=\"grayscale\", target_size=(28,28))\n",
        "    img_array = img_to_array(x)\n",
        "    # preprocessing if required\n",
        "    x_train.append(img_array)\n",
        "\n",
        "test_path = '/content/bioxtronomy/data/test/astronomy/'\n",
        "test_batch = os.listdir(test_path)\n",
        "x_test = []\n",
        "\n",
        "for sample in test_batch:\n",
        "    img_path = test_path + sample\n",
        "    x = image.load_img(img_path, color_mode=\"grayscale\", target_size=(28,28))\n",
        "    img_array = img_to_array(x)\n",
        "    # preprocessing if required\n",
        "    x_test.append(img_array)\n",
        "\n",
        "# finally converting list into numpy array\n",
        "trainX = np.array(x_train)\n",
        "testX = np.array(x_test)\n",
        "\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "\n",
        "# load the autoencoder model and index from disk\n",
        "print(\"[INFO] loading autoencoder and index...\")\n",
        "autoencoder = load_model(model)\n",
        "index = pickle.loads(open(index, \"rb\").read())\n",
        "\n",
        "# create the encoder model which consists of *just* the encoder\n",
        "# portion of the autoencoder\n",
        "encoder = Model(inputs=autoencoder.input, \n",
        "                outputs=autoencoder.get_layer(\"encoded\").output)\n",
        "\n",
        "# quantify the contents of our input testing images using the encoder\n",
        "print(\"[INFO] encoding testing images...\")\n",
        "features = encoder.predict(testX)\n",
        "\n",
        "queryIdxs = np.array([1,4,6,7])\n",
        "# loop over the testing indexes\n",
        "for i in queryIdxs:\n",
        "    # take the features for the current image, find all similar\n",
        "    # images in our dataset, and then initialize our list of result\n",
        "    # images\n",
        "    queryFeatures = features[i]\n",
        "    results = perform_search(queryFeatures, index, maxResults=225)\n",
        "    images = []\n",
        "\n",
        "    # loop over the results\n",
        "    # for (d, j) in results:\n",
        "    #     # grab the result image, convert it back to the range\n",
        "    #     # [0, 255], and then update the images list\n",
        "    #     image = (trainX[j] * 255).astype(\"uint8\")\n",
        "    #     image = np.dstack([image] * 3)\n",
        "    #     images.append(image)\n",
        "\n",
        "    # display the query image\n",
        "    query = (testX[i] * 255).astype(\"uint8\")\n",
        "    # img = cv2.imread(\"Query\", query)\n",
        "    cv2_imshow(query)\n",
        "    \n",
        "    # build a montage from the results and display it\n",
        "    montage = build_montages(images, (28, 28), (15, 15))[0]\n",
        "    # imgs = cv2.imread(\"Results\", montage)\n",
        "    cv2_imshow(montage)\n",
        "    cv2.waitKey(0)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading dataset...\n",
            "[INFO] loading autoencoder and index...\n",
            "[INFO] encoding testing images...\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f654f5a22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F654F016240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAGkCAIAAADxLsZiAAACGElEQVR4nO3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwI8BFUwAAS5XKdUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=420x420 at 0x7F654F0162E8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F654F0165C0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAGkCAIAAADxLsZiAAACGElEQVR4nO3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwI8BFUwAAS5XKdUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=420x420 at 0x7F654F0164E0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F654F016470>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAGkCAIAAADxLsZiAAACGElEQVR4nO3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwI8BFUwAAS5XKdUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=420x420 at 0x7F654F016240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F654F016240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAGkCAIAAADxLsZiAAACGElEQVR4nO3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwI8BFUwAAS5XKdUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=420x420 at 0x7F654F0162E8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwxzChuHnX6R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}